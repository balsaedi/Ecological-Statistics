# CORRELATION, COVARIANCE, GEOSTATISTICS
## INTRODUCTION
In this topic, we will focus on *Bivariate correlation* and *multivariate correlation*, that is, the correlation between two or multiple variables. 

Lets define correlation once again! **Correlation** is the degree if association of variables. 

**Correlation coefficient: ** is the quantifier that indicates the association of variables whether whether one variable is increasing/decreasing and the other one is increasing/decreasing or if there is no association at all. The correlation coefficient always ranges from -1 to 1 where the closer it gets to +1 means a stronger **positive correlation**(both variables increases/decreases at a concert) while it gets closer to -1 means a stronger **negative correlation** where one variable increases and the other variable decreases. A correlation close to zero from any direction($+_{ve}$ or $-_{ve}$) shows that there is little to no correlation between variables. 

**Multiple correlation** is where a group of variables (usually referred to as the predictor or X variables) to jointly relate to another variable (usually referred to as the response or Y variable),

**Partial correlation** is the correlation between any pair of variables, given the presence of the remaining variables. 

There are several methods to compute the correlation coefficient; 

1. *Pearson's* correlation coefficient. - satisfies linearity, normality and other parametric assumptions test. 
2. *Spearman's* correlation coefficient. - free from linearity, normality etc. conditions.
3. *Kendall's* correlation coefficient. - free from linearity, normality etc conditions.

## CORRELATION AND COVARIANCE 

Remember, **Correlation** is the degree of association between two variables - and the strength and direction of this relationship is captured by the **correlation coeeficient** which quantifies how the variables are related. 

Correlation can be *linear* or *non-linear* where the former refers to the proportional changes in variables(e.g doubling of one variables results in doubling the other) while the later refers to the relationship being not proportional(e.g doubling resulting into triple or fourfold change of the other). 

While correlation does not imply causation, understanding correlations can provide valuable insights. For example, a correlation between soil pH and aluminum levels in groundwater might indicate that lower pH levels increase aluminum dissolution, even though pH itself is not the direct cause of aluminum contamination.

**Covariance**,  on the other hand, measures the degree to which two variables change together. Unlike the correlation coefficient, covariance lacks a standardized scale, making it harder to interpret. The correlation coefficient can be derived by dividing the covariance by the product of the standard deviations of the two variables.

**Application of correlation** 

Correlation forms the foundation for many analyses, including regression, where relationships are used to predict one variable based on another. However, spurious correlations (associations without logical explanation) should be critically evaluated to avoid misleading conclusions. For instance, a correlation between the number of graduating students and basketball game wins is likely coincidental rather than meaningful.

In Summary, correlation provides a normalized measure of association, covariance gives an absolute value of joint variability. Together, these metrics are crucial for understanding relationships between variables and guiding further analyses.

Lets dive deep into exploring the correlation coefficient mentioned in the introduction.

### Pearson's Correlation Coefficient 

**Pearson’s correlation coefficient**, often referred to as *Pearson’s r* or the *product-moment correlation*, measures the strength and direction of a linear relationship between two variables. It works best for linear and monotonic relationships, where the association is consistently positive or negative.

A high pearson correlation will have the data points when plotted on a scatter plot to align in a straight line and have all points easily predicted/approximated by a straight line("regression line"). 

Pearson correlation is computed when the test or data satisfies the parametric assumptions, such that;

- Be from normally distributed populations.
- Have no significant outliers.
- Show consistent variance (homoscedasticity).

This type of correlation is sensitive to non-linear data or data containing missing values(e.g non-detects). Under such cases alternatives like Spearman or Kendall coefficients are recommended. 

The Pearsons correlation coeefficient is:

$$r = {1\over{n - 1}}{\sum^n_{i=1}[{{x_i - \overline{x}}\over{s_x}}][{{y_i - \overline{y}}\over{s_y}}]}$$

Where;

- $x_i$: the independent variable data value
- $\overline x$: the mean of independent data values 
- $y_i$: the dependent variable data value 
- $\overline y$: the mean of the dependent data values 
- $s_x$: The standard deviation of the independent variable 
- $s_y$: the standard deviation of the dependent variable 

ALternatively, it can be calculated as; 

$$r = {{\sum(x_i - \overline x)(y_i- \overline y)}\over{\sqrt{\sum{(x_i - \overline x)^2(y_i - \overline y)^2}}}}$$

Where; 

- $x_i$ and $y_i$: the data values for the two variables 
- $\overline x$ and $\overline y$: the mean values of the variables. 

If r's magnitude is; 

- 0.95 and above, this indicates a strong correlation.
- between 0.75 and below 0.95 , indicates a moderate correlation.
- below 0.5, therefore there is a weak correlation. 

**Significance Testing for Pearson’s Correlation Coefficient**

When working with real-world ecological data like the release of acidity of agricultural farms near zero grazing structures, significance testing helps determine whether the observed correlation between two variables in a sample reflects a true correlation in the population or is simply due to chance.

Here is a step by step process; 

1. *Forumalate the null hypothesis*

Null hypothesis ($H_0$):  There is no correlation between the two variables in the population (r = 0)

Alternate Hypothesis($H_a$): There is a strong correlation

2. *Compute the test statistic*

Test statistic ($t_r$) can be computed by; 

$$t_r = {{r\sqrt{n-2}}\over{\sqrt{1-r^2}}}$$

Where; 

- $r$: Sample correlation coefficient
- $n$: Number of paired data points

This formula adjusts $r$ for the sample size and expresses how extreme the observed correlation is.

3. *Compute the degree of freedom*

The degree of freedom is calculated by; $$df = n -2 $$

4. Determine the critical value, pvalue and make your decision


----------------------------**remember to put this into practice--------------------------------------------------

### Spearman's Correlaton Coeefficient 

## GEOSTATISTICS 




